{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Personalitics Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.) Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from scipy.stats import mode\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from utils import parse_type_personality_cafe, unpack_topic_user, unpack_comments, \\\n",
    "                  unpack_comment_user, html_to_text, parse_type_16personality\n",
    "from utils import TYPES\n",
    "import os\n",
    "from dask import dataframe  as dd\n",
    "\n",
    "OUTPUT_DIR = r'../output/'\n",
    "COMMENT_USER_DIR = OUTPUT_DIR + r'df_comment_user_chunks/'\n",
    "COMMENT_DIR = OUTPUT_DIR + r'df_comment_chunks/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [49:43, 93.24s/it] \n"
     ]
    }
   ],
   "source": [
    "df_chunks = pd.read_csv('../output/discussion_2.csv', chunksize=4000,\n",
    "                       usecols=['comment_list', 'url', 'id'])\n",
    "# List of columns of interest\n",
    "comment_user_cols = ['id', 'profileUrl', 'avatar', 'gender', 'reputation', 'type']\n",
    "comment_cols = ['id', 'approvedAtNice', 'answerBody', 'url']\n",
    "\n",
    "for i, chunk in tqdm(enumerate(df_chunks)):\n",
    "    # Unpack the comment json \n",
    "    chunk_comment = chunk[['comment_list', 'url']].apply(unpack_comments, axis=1)\n",
    "    chunk_comment = pd.concat(chunk_comment.values)\n",
    "    \n",
    "    # Unpack the comment_user json\n",
    "    chunk_comment_user = chunk_comment[['user', 'id']].apply(unpack_comment_user, axis=1)\n",
    "    \n",
    "\n",
    "    # Save into a csv file\n",
    "    chunk_comment_user[comment_user_cols].to_csv(COMMENT_USER_DIR + 'df_comment_user{}.csv'.format(i), index=False)\n",
    "    chunk_comment[comment_cols].to_csv(COMMENT_DIR + 'df_comment{}.csv'.format(i), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Unpack the topic_user column then merge it into the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_comment_df():\n",
    "    tmp_df_ls = []\n",
    "    for file_user, file_comment in tqdm(zip(os.listdir(COMMENT_USER_DIR), os.listdir(COMMENT_DIR))):\n",
    "        curr_file_user = os.path.join(COMMENT_USER_DIR, file_user)\n",
    "        curr_file_comment = os.path.join(COMMENT_DIR, file_comment)\n",
    "\n",
    "        tmp_df_comments_user = pd.read_csv(curr_file_user)\n",
    "        tmp_df_comment = pd.read_csv(curr_file_comment)\n",
    "        tmp_df = pd.merge(tmp_df_comment, tmp_df_comments_user, how='inner', on='id')\n",
    "        tmp_df_ls.append(tmp_df)\n",
    "    final_df = pd.concat(tmp_df_ls)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:12,  2.56it/s]\n"
     ]
    }
   ],
   "source": [
    "df_merged = get_comment_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.columns = list(map(lambda x: 'sub-'+ x, df_merged.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1169475, 9)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv(OUTPUT_DIR + r'comment_discussion.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Tweak memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged['sub-id'] = df_merged['sub-id'].astype('int64')\n",
    "# df_merged['sub-approved'] = df_merged['sub-approved'].astype('int8')\n",
    "# df_merged['sub-createdAtDiff'] = df_merged['sub-createdAtDiff'].astype('int32')\n",
    "# df_merged['sub-reportCount'] = df_merged['sub-reportCount'].astype('int32')\n",
    "# df_merged['sub-reviewed'] = df_merged['sub-reviewed'].astype('int8')\n",
    "# df_merged['sub-subCommentCount'] = df_merged['sub-subCommentCount'].astype('int32')\n",
    "# df_merged['sub-totalVotingScore'] = df_merged['sub-totalVotingScore'].astype('int32')\n",
    "# df_merged['sub-unavailable'] = df_merged['sub-unavailable'].astype('int8')\n",
    "# df_merged['sub-upvotedByUser'] = df_merged['sub-upvotedByUser'].astype('bool')\n",
    "\n",
    "# df_merged['sub-updatedByUser'] = df_merged['sub-updatedByUser'].astype('bool')\n",
    "# df_merged['sub-unread'] = df_merged['sub-unread'].astype('bool')\n",
    "# df_merged['sub-reportIgnored'] = df_merged['sub-reportIgnored'].astype('bool')\n",
    "# df_merged['sub-reportedByUser'] = df_merged['sub-reportedByUser'].astype('bool')\n",
    "# df_merged['sub-own'] = df_merged['sub-own'].astype('bool')\n",
    "# df_merged['sub-hasUnreadSubComments'] = df_merged['sub-hasUnreadSubComments'].astype('bool')\n",
    "# df_merged['sub-hasDisapprovalReason'] = df_merged['sub-hasDisapprovalReason'].astype('bool')\n",
    "# df_merged['sub-disapprovalReason'] = df_merged['sub-disapprovalReason'].fillna('N/A')\n",
    "# df_merged['sub-states'] = df_merged['sub-states'].apply(lambda x: json.dumps(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_mem_usage = df_merged.memory_usage().sum()\n",
    "# new_mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory_saved = (old_mem_usage - new_mem_usage)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Total Memory Usage saved:', round(memory_saved, 2), 'mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the modified DataFrame\n",
    "# df_merged.to_csv('../output/modified_comment.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Aggregating text posts based on User ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(x):\n",
    "    try:\n",
    "        return re.sub('\\..+', '', x)\n",
    "    except:\n",
    "        print(x)\n",
    "\n",
    "def aggregate_data(source):\n",
    "    if source == 'personalitycafe':\n",
    "        conn = sqlite3.connect('../output/project_mbti.db')\n",
    "        df_db = pd.read_sql('SELECT user_id, user_type, child_text, date, created_at FROM personalitics', con=conn)\n",
    "        temp_df = pd.read_csv('../output/personality_cafe.csv', usecols=['user_id', 'user_type', 'child_text', 'date', 'created_at'])\n",
    "        temp_df = pd.concat([temp_df, df_db])\n",
    "        temp_df = temp_df[~(temp_df.duplicated())]\n",
    "        temp_df = temp_df[~(temp_df['user_type'].isna())]\n",
    "        temp_df = temp_df[~(temp_df['child_text'].isna())]\n",
    "        temp_df['user_type'] = temp_df['user_type'].apply(parse_type_personality_cafe)\n",
    "        temp_df = temp_df[(temp_df['user_type'].isin(TYPES))]\n",
    "        has_yesterday = temp_df['date'].str.contains(r'Yesterday|Today')\n",
    "        temp_df.loc[has_yesterday, 'date'] = temp_df.loc[has_yesterday, 'date'].str.strip('Yesterday ').str.strip('Today ')\n",
    "        temp_df['created_at'] = temp_df['created_at'].apply(get_date)\n",
    "        temp_df.loc[has_yesterday, 'date'] = temp_df.loc[has_yesterday, 'created_at'].str.replace(r' \\d+:\\d+:\\d+', '') +  ' ' + temp_df.loc[has_yesterday, 'date'].astype(str)\n",
    "        temp_df['date'] = pd.to_datetime(temp_df['date'])\n",
    "        temp_df['dow'] = temp_df['date'].copy()\n",
    "        temp_df = temp_df[['user_id', 'child_text', 'date', 'dow', 'user_type']].groupby(['user_id', 'user_type'])\n",
    "        temp_df = temp_df.agg({'date': lambda x: x.dt.hour.median(),\n",
    "                               'child_text': '|||'.join,\n",
    "                               'dow': lambda z: mode(z.dt.dayofweek).mode[0]}).reset_index()\n",
    "        temp_df.to_csv('../output/aggregated/data_personalitycafe.csv', index=False)\n",
    "        \n",
    "    elif source == '16personalities_discussion_comments':\n",
    "        chunks = pd.read_csv('../output/comment_discussion.csv', \n",
    "                             usecols=['sub-approvedAtNice', 'sub-answerBody', 'sub-type', 'sub-profileUrl'],\n",
    "                             chunksize=4096)\n",
    "        temp_ls = []\n",
    "        for chunk in tqdm(chunks):\n",
    "            temp_df = chunk.drop(axis=1, index=chunk[chunk['sub-type'].isna()].index)\n",
    "            temp_df = temp_df.drop(axis=1, index=temp_df[temp_df['sub-answerBody'].isna()].index)\n",
    "            temp_df['sub-answerBody'] = temp_df['sub-answerBody'].apply(html_to_text)\n",
    "            temp_df['sub-approvedAtNice'] = pd.to_datetime(temp_df['sub-approvedAtNice'])\n",
    "            temp_df['sub-dow'] = temp_df['sub-approvedAtNice'].copy()\n",
    "            temp_df = temp_df[['sub-profileUrl', 'sub-answerBody', 'sub-approvedAtNice', 'sub-dow', 'sub-type']]\n",
    "            temp_ls.append(temp_df)\n",
    "            \n",
    "        temp_df = dd.from_pandas(pd.concat(temp_ls), 512, sort=False)\n",
    "        temp_df = temp_df.groupby(['sub-profileUrl', 'sub-type'])\n",
    "        temp_df = temp_df.agg({'sub-answerBody': '|||'.join, \n",
    "                               'sub-approvedAtNice': lambda x: x.dt.hour.median(),\n",
    "                               'sub-dow': lambda z: mode(z.dt.dayofweek).mode[0]}).compute().reset_index()\n",
    "        temp_df.to_csv('../output/aggregated/data_discussion_16personalities.csv', index=False)\n",
    "        \n",
    "    elif source == '16personalities_pub_comments':\n",
    "        temp_df = pd.read_csv('../output/sixteenpersonalities.csv')\n",
    "        temp_df = temp_df[~(temp_df['child_text'].isna())]\n",
    "        temp_df = temp_df[~(temp_df['user_type'].isna())]\n",
    "        temp_df['user_type'] = temp_df['user_type'].apply(parse_type_16personality)\n",
    "        temp_df = temp_df[(temp_df['user_type'].isin(TYPES))]\n",
    "        temp_df = temp_df[['user_id', 'child_text', 'user_type']].groupby(['user_id', 'user_type']).agg({'child_text': ' '.join}).reset_index()[['child_text', 'user_type']]\n",
    "        temp_df.to_csv('../output/aggregated/data_pub_16personalities.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aggregate_data('personalitycafe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "286it [02:48,  1.70it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1edb38becc33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maggregate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'16personalities_discussion_comments'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-2a1e55321521>\u001b[0m in \u001b[0;36maggregate_data\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_ls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sub-profileUrl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sub-type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         temp_df = temp_df.agg({'sub-answerBody': '|||'.join, \n",
      "\u001b[1;32mc:\\users\\razer\\desktop\\project_mbti\\venv\\lib\\site-packages\\dask\\dataframe\\io\\io.py\u001b[0m in \u001b[0;36mfrom_pandas\u001b[1;34m(data, npartitions, chunksize, sort, name)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0mchunksize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"from_pandas-\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\desktop\\project_mbti\\venv\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    668\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\desktop\\project_mbti\\venv\\lib\\site-packages\\dask\\utils.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \"\"\"\n\u001b[0;32m    505\u001b[0m         \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\desktop\\project_mbti\\venv\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mnormalize_dataframe\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    822\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalize_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mnormalize_token\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtensionArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\desktop\\project_mbti\\venv\\lib\\site-packages\\dask\\utils.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \"\"\"\n\u001b[0;32m    505\u001b[0m         \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\desktop\\project_mbti\\venv\\lib\\site-packages\\dask\\base.py\u001b[0m in \u001b[0;36mnormalize_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[1;31m# string fast-path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m                     data = hash_buffer_hex(\n\u001b[1;32m--> 875\u001b[1;33m                         \"-\".join(x.flat).encode(\n\u001b[0m\u001b[0;32m    876\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"surrogatepass\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m                         )\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "aggregate_data('16personalities_discussion_comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_data('16personalities_pub_comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv('../output/comment_discussion.csv', nrows=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "286it [02:46,  1.71it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = pd.read_csv('../output/comment_discussion.csv', \n",
    "                     usecols=['sub-approvedAtNice', 'sub-answerBody', 'sub-type', 'sub-profileUrl'],\n",
    "                     chunksize=4096)\n",
    "temp_ls = []\n",
    "for chunk in tqdm(chunks):\n",
    "    temp_df = chunk.drop(axis=1, index=chunk[chunk['sub-type'].isna()].index)\n",
    "    temp_df = temp_df.drop(axis=1, index=temp_df[temp_df['sub-answerBody'].isna()].index)\n",
    "    temp_df['sub-answerBody'] = temp_df['sub-answerBody'].apply(html_to_text)\n",
    "    temp_df['sub-approvedAtNice'] = pd.to_datetime(temp_df['sub-approvedAtNice'])\n",
    "    temp_df['sub-dow'] = temp_df['sub-approvedAtNice'].copy()\n",
    "    temp_df = temp_df[['sub-profileUrl', 'sub-answerBody', 'sub-approvedAtNice', 'sub-dow', 'sub-type']]\n",
    "    temp_ls.append(temp_df)\n",
    "\n",
    "temp_df = pd.concat(temp_ls)\n",
    "temp_df = temp_df.set_index(['sub-profileUrl', 'sub-type'])\n",
    "temp_df['sub-approvedAtNice'] = temp_df['sub-approvedAtNice'].dt.dayofweek.astype('int')\n",
    "temp_df['sub-dow'] = temp_df['sub-dow'].dt.hour.astype('int')\n",
    "temp_df.groupby(temp_df.index).agg({'sub-answerBody': '|||'.join, \n",
    "                                    'sub-approvedAtNice': lambda x: x.median(),\n",
    "                                    'sub-dow': lambda z: mode(z).mode[0]}, observed=True)\n",
    "# temp_df.to_csv('../output/aggregated/data_discussion_16personalities.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.to_csv('../output/discussion_comments_16personalities.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv('../output/aggregated/data_personalitycafe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22403,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df['child_text'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
